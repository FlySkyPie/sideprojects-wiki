拿 Minecraft 來做機器學習訓練 AI 的專案不少，不過它們並不是沈浸式 (Immersive Experience) 的。在 Minecraft 之中除了第一人稱視角 (PFV, First-person view) 之外還有大量基於滑鼠操作的 UX。

對增強式學習而言，玩家與環境的互動來自操作 (Action) 與觀察 (Observe)，對人類而言可以觀察到 Minecraft 的兩個資訊：第一人稱 3D 渲染與 HUD/UI；而操作同樣有兩個：第一人稱控制器與滑鼠。

但是對大多數的 Minecraft AI 專案而言，AI 觀察與操作都與人類大相逕庭。以 [Baritone](https://github.com/cabaletta/baritone) （知名 Minecraft 自動外掛）為例，程式是直接讀取地圖上的方塊資料來規劃路徑，操作則是直接丟封包給伺服器，所以可以作到諸如隔著牆壁打開箱子之類的事情。

另外一個機器學習專案 [Voyager](https://github.com/MineDojo/Voyager)則是包了一層的 Minecraft Client，真正操作與觀察的程式是一個叫做 [Mineflayer](https://github.com/PrismarineJS/mineflayer) 的 Javascript 函式庫，與 Baritone 相同，直接讀取地圖資訊並呼叫函式來丟封包給伺服器完成操作。不同的是 Voyager 透過機器學習的 GPT-4 模型負責撰寫 Javascript 程式碼來控制玩家。

據我所知唯一使用視覺化資料的是一個名為 [MineRL](https://minerl.io/) 的專案，它其實是一個 AI 競賽，目標就是用 AI 玩 Minecraft 挖到鑽石，但是 AI 只能跟玩家一樣觀察到一張 3D 渲染的第一人稱畫面，即便如此，它的操作依然不是沈浸式的[^minerl-api]：

![](#03_minerl-action.webp)

它直接提供一個函式，當玩家附近有工作台並且身上有足夠的原料，就直接完成合成，以人類可以理解的體驗就像是：
> 你桌上放著一排按鈕，只要附近有工作台，按下對應的按鈕自動完成合成，過程中於需操作遊戲中的那個操作界面用滑鼠拖拉材料。

因為 MineRL 設計上就是為了挖到鑽石，因此只需要提供部份必要的界面 (Interface) 供玩家操作即可。

「完全視覺化」意味著在這個專案中，視覺資料是 AI 唯一能夠獲得環境資訊的方式，FPV 控制器是 AI 唯一能和環境互動的手段，因此，沒有血量或體力值的變數、沒有額外的裝備欄變數、沒有任何基於滑鼠操作的彈出視窗、沒有快捷的 function call。

「完全視覺化」意味著必須重新設計一套完全基於 FPV 控制器的遊戲體驗。

[^minerl-api]: MineRL 0.3.0 documentation. (William H. Guss, Brandon Houghton). Retrieved 2023-10-08, from https://minerl.io/docs/environments/index.html#id20